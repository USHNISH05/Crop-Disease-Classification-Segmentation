{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2583839,"sourceType":"datasetVersion","datasetId":1545227},{"sourceId":9476761,"sourceType":"datasetVersion","datasetId":5763793},{"sourceId":120484,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":101347,"modelId":125542},{"sourceId":120506,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":101366,"modelId":125561}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport os\nimport numpy as np\nfrom tensorflow.keras.layers import Input, Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import Sequence","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:59:40.032405Z","iopub.execute_input":"2024-09-25T15:59:40.032803Z","iopub.status.idle":"2024-09-25T15:59:40.044734Z","shell.execute_reply.started":"2024-09-25T15:59:40.032765Z","shell.execute_reply":"2024-09-25T15:59:40.043646Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/input/segmentation_unet/keras/default/1/unet_main.keras')","metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:19:04.703271Z","iopub.execute_input":"2024-09-25T16:19:04.703677Z","iopub.status.idle":"2024-09-25T16:19:05.091229Z","shell.execute_reply.started":"2024-09-25T16:19:04.703638Z","shell.execute_reply":"2024-09-25T16:19:05.090150Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Custom Data Generator for Segmentation\nclass SegmentationDataGenerator(Sequence):\n    def __init__(self, image_dir, mask_dir, batch_size=32, image_size=(256, 256)):\n        self.image_paths = [os.path.join(image_dir, fname) for fname in sorted(os.listdir(image_dir)) if fname.endswith('.jpg')]\n        self.mask_paths = [os.path.join(mask_dir, fname) for fname in sorted(os.listdir(mask_dir)) if fname.endswith('.png')]\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.indexes = np.arange(len(self.image_paths))\n\n        # Check that number of images matches number of masks\n        assert len(self.image_paths) == len(self.mask_paths), \"Mismatch in number of images and masks\"\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_images = [self.load_image(self.image_paths[i]) for i in batch_indexes]\n        batch_masks = [self.load_mask(self.mask_paths[i]) for i in batch_indexes]\n        \n        # Debugging: Print batch shapes\n#         print(f\"Batch images shape: {np.array(batch_images).shape}\")\n#         print(f\"Batch masks shape: {np.array(batch_masks).shape}\")\n\n        return np.array(batch_images), np.array(batch_masks)\n\n    def load_image(self, path):\n        img = load_img(path, target_size=self.image_size)\n        img_array = img_to_array(img)\n        return img_array / 255.0  # Normalize\n\n    def load_mask(self, path):\n        mask = load_img(path, target_size=self.image_size, color_mode='grayscale')  # Load mask as grayscale\n        mask_array = img_to_array(mask).astype(np.uint8)\n\n        # Convert mask values to integers (assuming 38 is the only non-zero value)\n        mask_array = np.where(mask_array == 38, 1, 0)  # Map pixel value 38 to 1, all else to 0\n\n        return mask_array","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:59:51.280195Z","iopub.execute_input":"2024-09-25T15:59:51.280573Z","iopub.status.idle":"2024-09-25T15:59:51.292604Z","shell.execute_reply.started":"2024-09-25T15:59:51.280537Z","shell.execute_reply":"2024-09-25T15:59:51.291536Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define your validation directories here\nval_image_dir = '/kaggle/input/leaf-disease-segmentation-dataset/data/data/images'  # .jpg images\nval_mask_dir = '/kaggle/input/leaf-disease-segmentation-dataset/data/data/masks'  # .png masks\n\n# Create validation data generator\nval_gen = SegmentationDataGenerator(\n    image_dir=val_image_dir,\n    mask_dir=val_mask_dir,\n    batch_size=16,  # Same batch size as training\n    image_size=(256, 256)\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:18:05.825114Z","iopub.execute_input":"2024-09-25T16:18:05.826048Z","iopub.status.idle":"2024-09-25T16:18:06.180758Z","shell.execute_reply.started":"2024-09-25T16:18:05.826004Z","shell.execute_reply":"2024-09-25T16:18:06.179937Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nval_loss, val_accuracy = loaded_model.evaluate(\n    val_gen,\n    steps=len(val_gen)  # Ensure all validation data is evaluated\n)\n\n# Print the results\nprint(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:19:08.992505Z","iopub.execute_input":"2024-09-25T16:19:08.992890Z","iopub.status.idle":"2024-09-25T16:19:15.081956Z","shell.execute_reply.started":"2024-09-25T16:19:08.992853Z","shell.execute_reply":"2024-09-25T16:19:15.080924Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9572 - loss: 0.1069\nValidation Loss: 0.10505835711956024\nValidation Accuracy: 0.9581560492515564\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\n# Function to get predictions and true masks\ndef get_predictions_and_true_masks(loaded_model, val_gen):\n    all_preds = []\n    all_true_masks = []\n\n    for i in range(len(val_gen)):\n        images, true_masks = val_gen[i]\n        preds = loaded_model.predict(images)\n        preds = (preds > 0.5).astype(np.uint8)  # Convert probabilities to binary masks\n\n        all_preds.append(preds)\n        all_true_masks.append(true_masks)\n\n    # Concatenate all batches\n    return np.concatenate(all_preds, axis=0), np.concatenate(all_true_masks, axis=0)\n\n# Get predictions and true masks\npredicted_masks, true_masks = get_predictions_and_true_masks(loaded_model, val_gen)\n\n# Flatten the predictions and true masks for classification report\npredicted_masks_flat = predicted_masks.flatten()\ntrue_masks_flat = true_masks.flatten()\n\n# Create classification report\nreport = classification_report(true_masks_flat, predicted_masks_flat, target_names=['Background', 'Disease'])\n\n# Print the classification report\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:19:25.240034Z","iopub.execute_input":"2024-09-25T16:19:25.241050Z","iopub.status.idle":"2024-09-25T16:22:34.788561Z","shell.execute_reply.started":"2024-09-25T16:19:25.241005Z","shell.execute_reply":"2024-09-25T16:22:34.787269Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n              precision    recall  f1-score   support\n\n  Background       0.97      0.98      0.98  32532237\n     Disease       0.91      0.81      0.86   6002931\n\n    accuracy                           0.96  38535168\n   macro avg       0.94      0.90      0.92  38535168\nweighted avg       0.96      0.96      0.96  38535168\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# Function to calculate the evaluation metrics\ndef evaluate_segmentation_metrics(true_masks, predicted_masks):\n    # Flatten the arrays\n    true_masks_flat = true_masks.flatten()\n    predicted_masks_flat = predicted_masks.flatten()\n    \n    # Calculate TP, TN, FP, FN\n    TP = np.sum((true_masks_flat == 1) & (predicted_masks_flat == 1))\n    TN = np.sum((true_masks_flat == 0) & (predicted_masks_flat == 0))\n    FP = np.sum((true_masks_flat == 0) & (predicted_masks_flat == 1))\n    FN = np.sum((true_masks_flat == 1) & (predicted_masks_flat == 0))\n    \n    # Pixel Accuracy\n    total_pixels = true_masks_flat.size\n    pixel_accuracy = (TP + TN) / total_pixels\n    \n    # IoU\n    IoU = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0.0\n    \n    # Dice Coefficient\n    dice_coefficient = (2 * TP) / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0.0\n    \n    # Precision\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    \n    # Recall\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    \n    # F1 Score\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n\n    return {\n        'Pixel Accuracy': pixel_accuracy,\n        'IoU': IoU,\n        'Dice Coefficient': dice_coefficient,\n        'Precision': precision,\n        'Recall': recall,\n        'F1 Score': f1\n    }\n\n# Get predictions from the validation set\npredicted_masks, true_masks = get_predictions_and_true_masks(loaded_model, val_gen)\n\n# Evaluate the model on the metrics\nmetrics = evaluate_segmentation_metrics(true_masks, predicted_masks)\n\n# Print the evaluation metrics\nfor metric, value in metrics.items():\n    print(f\"{metric}: {value:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:23:55.528406Z","iopub.execute_input":"2024-09-25T16:23:55.528819Z","iopub.status.idle":"2024-09-25T16:24:04.202497Z","shell.execute_reply.started":"2024-09-25T16:23:55.528780Z","shell.execute_reply":"2024-09-25T16:24:04.201463Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\nPixel Accuracy: 0.9582\nIoU: 0.7518\nDice Coefficient: 0.8583\nPrecision: 0.9082\nRecall: 0.8136\nF1 Score: 0.8583\n","output_type":"stream"}]}]}