{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","from tensorflow.keras.layers import Input, Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import Sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_unet_model(input_shape, n_classes):\n","    img_input = Input(shape=input_shape)\n","\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n","    conv1 = Dropout(0.2)(conv1)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D((2, 2))(conv1)\n","\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Dropout(0.2)(conv2)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D((2, 2))(conv2)\n","\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Dropout(0.2)(conv3)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","\n","    up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n","    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n","    conv4 = Dropout(0.2)(conv4)\n","    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n","\n","    up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n","    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n","    conv5 = Dropout(0.2)(conv5)\n","    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n","\n","    out = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv5)\n","\n","    model = Model(inputs=img_input, outputs=out)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Custom Data Generator for Segmentation\n","class SegmentationDataGenerator(Sequence):\n","    def __init__(self, image_dir, mask_dir, batch_size=32, image_size=(256, 256)):\n","        self.image_paths = [os.path.join(image_dir, fname) for fname in sorted(os.listdir(image_dir)) if fname.endswith('.jpg')]\n","        self.mask_paths = [os.path.join(mask_dir, fname) for fname in sorted(os.listdir(mask_dir)) if fname.endswith('.png')]\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.indexes = np.arange(len(self.image_paths))\n","\n","        # Check that number of images matches number of masks\n","        assert len(self.image_paths) == len(self.mask_paths), \"Mismatch in number of images and masks\"\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.image_paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","        batch_images = [self.load_image(self.image_paths[i]) for i in batch_indexes]\n","        batch_masks = [self.load_mask(self.mask_paths[i]) for i in batch_indexes]\n","        \n","        # Debugging: Print batch shapes\n","#         print(f\"Batch images shape: {np.array(batch_images).shape}\")\n","#         print(f\"Batch masks shape: {np.array(batch_masks).shape}\")\n","\n","        return np.array(batch_images), np.array(batch_masks)\n","\n","    def load_image(self, path):\n","        img = load_img(path, target_size=self.image_size)\n","        img_array = img_to_array(img)\n","        return img_array / 255.0  # Normalize\n","\n","    def load_mask(self, path):\n","        mask = load_img(path, target_size=self.image_size, color_mode='grayscale')  # Load mask as grayscale\n","        mask_array = img_to_array(mask).astype(np.uint8)\n","\n","        # Convert mask values to integers (assuming 38 is the only non-zero value)\n","        mask_array = np.where(mask_array == 38, 1, 0)  # Map pixel value 38 to 1, all else to 0\n","\n","        return mask_array"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define your directories here\n","image_dir = '/kaggle/input/leaf-disease-segmentation-dataset/aug_data/aug_data/images'  # .jpg images\n","mask_dir = '/kaggle/input/leaf-disease-segmentation-dataset/aug_data/aug_data/masks'  # .png masks"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create data generator\n","train_gen = SegmentationDataGenerator(\n","    image_dir=image_dir,\n","    mask_dir=mask_dir,\n","    batch_size=16,\n","    image_size=(256, 256)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create the U-Net model\n","model = create_unet_model(input_shape=(256, 256, 3), n_classes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","# Example usage\n","def train_model(model, train_gen, epochs):\n","    optimizer = Adam(learning_rate=1e-4)  # Lower the learning rate\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    model.fit(\n","        train_gen,\n","        epochs=epochs,\n","        steps_per_epoch=len(train_gen)\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the model\n","train_model(\n","    model,\n","    train_gen,\n","    epochs=500\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('unet_500.keras')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1545227,"sourceId":2583839,"sourceType":"datasetVersion"},{"datasetId":5662155,"sourceId":9342817,"sourceType":"datasetVersion"},{"datasetId":5662890,"sourceId":9343780,"sourceType":"datasetVersion"},{"datasetId":5715011,"sourceId":9411272,"sourceType":"datasetVersion"},{"datasetId":5719444,"sourceId":9417359,"sourceType":"datasetVersion"},{"datasetId":5719931,"sourceId":9417966,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":121533,"modelInstanceId":97347,"sourceId":115877,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
